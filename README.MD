# Emotion Detection for Metahuman

Capstone project exploring emotion mimicking abilities of metahumans. 

Group Members: Prem Patel (Prem-ium), Gabe Vindas (GabeV95), Matthew , & Dustin

### Installation
Run locally:
1. Clone this repository, cd into it, and install dependancies:
```sh
   git clone https://github.com/Prem-ium/EmotionDetection.git
   cd EmotionDetection
   pip install -r requirements.txt
   ```
2. Configure your `.env` file (See below and example for options)
3. Run the main script:
```sh
   python emotional-detection-main.py
```

### Enviornmental Variables
Configure your variables in a .env file within the same directory.

`HEADLESS`=True or False. Whether to open a GUI for testing webcam accuracy. Defaults to True.

`PRODUCTION`= True or False. Whether the program is running in Unreal Engine or not.

`DELAY`= Integer value of how many seconds the program will wait before starting the next iteration

# Example Output(s)

This section contains example outputs generated by running the command line interface of our application. These outputs demonstrate the variety of visualizations and reports that our application can produce.

## Neutral 
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Neutral.png" width="500">

## Happy
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Happy.png" width="500">

## Fear
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Fear.png" width="500">

## Sad
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Sad.png" width="500">

## Surprised
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Surprised.png" width="500">

