# Emotion Detection for Metahuman

Capstone project exploring emotion mimicking abilities of metahumans. 

Group Members: Prem Patel (Prem-ium), Gabe Vindas (GabeV95), Matthew , & Dustin

### Installation
Run locally:
1. Clone this repository, cd into it, and install dependancies:
```sh
   git clone https://github.com/Prem-ium/EmotionDetection.git
   cd EmotionDetection
   pip install -r requirements.txt
   ```
2. Configure your `.env` file (See below and example for options)
3. Run the main script:
```sh
   python emotional-detection-main.py
```

### Enviornmental Variables
Configure your variables in a .env file within the same directory.

`HEADLESS`=True or False. Whether to open a GUI for testing webcam accuracy. Defaults to True.

# Example Output(s)

This section contains example outputs generated by running the command line interface of our application. These outputs demonstrate the variety of visualizations and reports that our application can produce.

## Neautral 
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Neautral.png" width="500">

## Happy
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Happy.png" width="500">

## Fear
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Fear.png" width="500">

## Sad
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Sad.png" width="500">

## Surprised
<img src="https://raw.githubusercontent.com/Prem-ium/EmotionDetection/main/output-examples/Surprised.png" width="500">

